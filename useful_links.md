# Полезные ссылки

В этом документе собраны полезные ссылки для работы с речевыми технологиями и обработкой аудио.

## Таблица ссылок

| Ссылка | Описание | Теги |
|--------|----------|------|
| [Open STT](https://github.com/snakers4/open_stt) | * Крупнейший открытый датасет для русского STT<br>* ~16 миллионов высказываний<br>* ~20 000 часов аудио<br>* 2.3 ТБ в формате WAV, 356 ГБ в формате OPUS<br>* Включает уникальный домен - публичную речь<br>* Большой радио-датасет с 10 000+ часов<br>* Утилиты для работы с форматом OPUS | #русский #датасет #stt #asr #speech_recognition #open_data |
| [whisper.cpp](https://github.com/ggerganov/whisper.cpp) | * C/C++ реализация модели Whisper от OpenAI<br>* Не требует внешних зависимостей<br>* Оптимизация для Apple Silicon через ARM NEON, Accelerate, Metal и Core ML<br>* Поддержка AVX и VSX инструкций<br>* Смешанная точность F16/F32<br>* Квантизация в целочисленный формат<br>* Поддержка множества платформ (macOS, iOS, Android, Linux, Windows, и др.)<br>* Эффективное GPU-ускорение для NVIDIA | #whisper #cpp #speech_recognition #cross_platform #performance #gpu_acceleration |
| [OpenAI Whisper](https://github.com/openai/whisper) | * Универсальная модель распознавания речи от OpenAI<br>* Обучена на большом наборе разнообразных аудиоданных<br>* Многозадачная модель с поддержкой распознавания речи на разных языках<br>* Поддерживает распознавание речи, перевод речи и идентификацию языка<br>* Python-реализация с открытым исходным кодом | #whisper #openai #speech_recognition #multilingual #translation #open_source |
| [Golos](https://github.com/salute-developers/golos) | * Российский датасет для исследований в области распознавания речи<br>* Разработан Salute Developers (SberDevices)<br>* Включает также датасет Dusha для задач распознавания эмоций в речи<br>* Открытая лицензия для исследовательских и коммерческих целей | #русский #датасет #speech_recognition #sber #emotions #golos |
| [SOVA Dataset](https://github.com/sovaai/sova-dataset) | * Бесплатный публичный STT/ASR датасет<br>* Включает русский, английский и китайский языки<br>* ~32 328 часов аудио<br>* ~3,21 ТБ в формате WAV | #multilingual #датасет #stt #asr #русский #english #chinese #speech_recognition |
| [Common Voice 17.0](https://huggingface.co/datasets/mozilla-foundation/common_voice_17_0) | * Многоязычный датасет от Mozilla Foundation<br>* ~31 175 часов записей в 124 языках<br>* ~20 408 валидированных часов<br>* Включает демографические метаданные (возраст, пол, акцент)<br>* Разработан сообществом на основе пожертвований<br>* Открытая некоммерческая инициатива | #multilingual #датасет #speech_recognition #mozilla #community #open_data |
| [Emilia Dataset](https://huggingface.co/datasets/amphion/Emilia-Dataset) | * Обширный многоязычный датасет для генерации речи<br>* Более 200 000 часов данных (Emilia-Large)<br>* Поддерживает 6 языков: английский, китайский, немецкий, французский, японский, корейский<br>* Разнообразные стили речи из различных источников (видеоплатформы, подкасты)<br>* Включает Emilia-Pipe - открытую систему препроцессинга для обработки речевых данных | #multilingual #датасет #speech_generation #tts #language_diversity #large_scale |
| [VoxPopuli](https://github.com/facebookresearch/voxpopuli) | * Многоязычный речевой корпус от Facebook Research<br>* 400 000 часов нетранскрибированных данных на 23 языках<br>* 1 800 часов транскрибированных данных на 16 языках<br>* 17 300 часов данных речь-в-речь для 15×15 языковых направлений<br>* 29 часов транскрибированной речи для исследования распознавания акцентированной английской речи<br>* Данные собраны из записей мероприятий Европейского Парламента | #multilingual #датасет #speech_recognition #european_languages #facebook #representation_learning |
| [Whisper large-v3](https://huggingface.co/openai/whisper-large-v3) | * Последняя версия модели Whisper от OpenAI<br>* Поддерживается библиотекой Hugging Face Transformers<br>* Может транскрибировать аудио произвольной длины<br>* Поддерживает различные стратегии декодирования (temperature fallback, condition on previous tokens)<br>* Автоматически определяет язык исходного аудио<br>* Поддерживает задачи транскрипции и перевода речи<br>* Оптимизирован для работы на GPU с использованием float16 | #whisper #openai #speech_recognition #multilingual #huggingface #transformers #asr |
| [W2v-BERT 2.0](https://huggingface.co/facebook/w2v-bert-2.0) | * Речевой энкодер на основе Conformer от Facebook<br>* Предобучен на 4.5 миллионах часов неразмеченных аудиоданных<br>* Охватывает более 143 языков<br>* Требует дообучения для конкретных задач (ASR, классификация аудио)<br>* Используется в моделях Seamless<br>* Поддерживается библиотекой Hugging Face Transformers<br>* Может извлекать аудио-эмбеддинги из верхнего слоя | #speech_encoder #facebook #w2v_bert #multilingual #huggingface #transformers #pretraining |
| [SeamlessM4T v2 Large](https://huggingface.co/facebook/seamless-m4t-v2-large) | * Многозадачная многоязычная модель от Facebook для речевого перевода<br>* Поддерживает преобразование речь-в-речь, речь-в-текст, текст-в-речь и текст-в-текст<br>* Доступны метрики производительности и тестовые наборы данных<br>* Возможность дообучения для конкретных задач<br>* Включает утилиты для оценки и настройки<br>* Использует энкодер W2v-BERT 2.0 в основе<br>* Открытый исходный код и документация | #multilingual #speech_translation #facebook #seamless #multi_task #huggingface |
| [Canary 1B](https://huggingface.co/nvidia/canary-1b) | * Модель энкодер-декодер от NVIDIA для распознавания и перевода речи<br>* Использует архитектуру FastConformer энкодер + Transformer декодер<br>* 24 слоя энкодера и 24 слоя декодера<br>* Поддерживает задачи ASR (автоматическое распознавание речи) и AST (автоматический перевод речи)<br>* Использует конкатенированный токенизатор SentencePiece для масштабирования на больше языков<br>* Поддерживается библиотекой NVIDIA NeMo<br>* Масштабируемая архитектура | #nvidia #speech_recognition #speech_translation #nemo #transformer #asr #ast |
| [Speaker Diarization 3.1](https://huggingface.co/pyannote/speaker-diarization-3.1) | * Система для диаризации говорящих (определение кто и когда говорит в аудио)<br>* Разработана pyannote.audio версии 3.1<br>* Поддерживает обработку на GPU для ускорения<br>* Возможность контроля количества говорящих<br>* Возможность мониторинга прогресса обработки<br>* Вывод результатов в формате RTTM<br>* Требуется токен доступа Hugging Face для использования | #speaker_diarization #pyannote #audio_processing #huggingface #speech_segmentation #audio_analysis #conversation_analysis |
